{
  "master": {
    "tasks": [
      {
        "id": 11,
        "title": "Set up Crossplane with Required Providers",
        "description": "Install and configure Crossplane with necessary providers (Helm, AWS, GitHub, Kubernetes) in the management cluster to enable infrastructure provisioning via CRDs.",
        "details": "Install Crossplane v1.14.0+ using Helm chart with the following providers:\n1. provider-helm v0.16.0+ for deploying Helm charts\n2. provider-aws v0.43.0+ for AWS resources (API Gateway, IAM)\n3. provider-github v0.7.0+ for repository operations\n4. provider-kubernetes v0.10.0+ for K8s resource management\n\nImplementation steps:\n```bash\n# Install Crossplane using Helm\nhelm repo add crossplane-stable https://charts.crossplane.io/stable\nhelm install crossplane crossplane-stable/crossplane --namespace crossplane-system --create-namespace --version 1.14.0\n\n# Install providers\nkubectl apply -f - <<EOF\napiVersion: pkg.crossplane.io/v1\nkind: Provider\nmetadata:\n  name: provider-aws\nspec:\n  package: xpkg.upbound.io/crossplane-contrib/provider-aws:v0.43.0\n---\napiVersion: pkg.crossplane.io/v1\nkind: Provider\nmetadata:\n  name: provider-helm\nspec:\n  package: xpkg.upbound.io/crossplane-contrib/provider-helm:v0.16.0\n---\napiVersion: pkg.crossplane.io/v1\nkind: Provider\nmetadata:\n  name: provider-github\nspec:\n  package: xpkg.upbound.io/crossplane-contrib/provider-github:v0.7.0\n---\napiVersion: pkg.crossplane.io/v1\nkind: Provider\nmetadata:\n  name: provider-kubernetes\nspec:\n  package: xpkg.upbound.io/crossplane-contrib/provider-kubernetes:v0.10.0\nEOF\n```\n\nConfigure provider credentials using ProviderConfig resources for each provider. Set up appropriate IAM roles and service accounts with least privilege principles. For AWS, use IRSA (IAM Roles for Service Accounts) to avoid storing credentials.",
        "testStrategy": "1. Verify all providers are installed and in 'Healthy' state using `kubectl get providers`\n2. Test each provider with a simple resource creation (e.g., create a test S3 bucket with AWS provider)\n3. Validate provider permissions by attempting operations that should succeed and fail\n4. Create a simple Composition and XRD to verify Crossplane's core functionality",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Install Crossplane Core Using Helm",
            "description": "Set up the Crossplane core components in the management cluster using Helm chart version 1.14.0+.",
            "dependencies": [],
            "details": "1. Add the Crossplane Helm repository\n2. Create a dedicated namespace 'crossplane-system'\n3. Install Crossplane using Helm with version 1.14.0 or newer\n4. Verify the installation by checking that all Crossplane pods are running\n5. Ensure the Crossplane CRDs are properly installed",
            "status": "done",
            "testStrategy": "Verify installation by running `kubectl get pods -n crossplane-system` and ensure all pods are in Running state. Also check CRDs with `kubectl get crds | grep crossplane` to confirm proper installation."
          },
          {
            "id": 2,
            "title": "Install Required Crossplane Providers",
            "description": "Install the four required Crossplane providers: AWS, Helm, GitHub, and Kubernetes with their specified versions.",
            "dependencies": [
              1
            ],
            "details": "Create and apply Provider resources for each required provider with the specified versions:\n1. provider-aws v0.43.0+\n2. provider-helm v0.16.0+\n3. provider-github v0.7.0+\n4. provider-kubernetes v0.10.0+\n\nUse the kubectl apply command with the YAML configuration as provided in the task description. Monitor the provider installation status until all providers are healthy.",
            "status": "done",
            "testStrategy": "Check provider installation status with `kubectl get providers` and verify all providers are in 'Healthy' state. Also check for provider controller pods with `kubectl get pods -n crossplane-system | grep provider`."
          },
          {
            "id": 3,
            "title": "Configure AWS Provider with IRSA",
            "description": "Set up AWS provider credentials using IAM Roles for Service Accounts (IRSA) to avoid storing credentials directly.",
            "dependencies": [
              2
            ],
            "details": "1. Create an IAM role with necessary permissions following least privilege principles\n2. Configure IRSA for the Crossplane AWS provider:\n   - Create a service account in the crossplane-system namespace\n   - Annotate the service account with the IAM role ARN\n   - Update the AWS provider deployment to use this service account\n3. Create and apply an AWS ProviderConfig that references the service account\n4. Test the AWS provider configuration with a simple AWS resource creation",
            "status": "done",
            "testStrategy": "Create a simple AWS resource (like an S3 bucket) using Crossplane to verify the provider can successfully authenticate with AWS."
          },
          {
            "id": 4,
            "title": "Configure Remaining Providers (Helm, GitHub, Kubernetes)",
            "description": "Set up credentials and configurations for the Helm, GitHub, and Kubernetes providers.",
            "dependencies": [
              2
            ],
            "details": "For each provider:\n\n1. Helm Provider:\n   - Create a ProviderConfig that uses in-cluster configuration\n   - Configure any necessary release repositories\n\n2. GitHub Provider:\n   - Create a GitHub personal access token with appropriate permissions\n   - Store the token as a Kubernetes secret\n   - Create a ProviderConfig that references this secret\n\n3. Kubernetes Provider:\n   - Set up a ProviderConfig using in-cluster configuration for same-cluster resources\n   - For multi-cluster management, create kubeconfig secrets and reference them in additional ProviderConfigs",
            "status": "done",
            "testStrategy": "Test each provider by creating a simple resource:\n- Helm: Deploy a simple chart\n- GitHub: List a repository\n- Kubernetes: Create a ConfigMap via Crossplane"
          },
          {
            "id": 5,
            "title": "Implement Least Privilege Security Controls",
            "description": "Review and refine all provider configurations to ensure they follow least privilege principles and implement proper security controls.",
            "dependencies": [
              3,
              4
            ],
            "details": "1. Audit all provider configurations and associated IAM roles/permissions\n2. Restrict AWS IAM role permissions to only what's necessary for the specific resources being managed\n3. Limit GitHub token permissions to only required scopes\n4. For Kubernetes provider, ensure RBAC is properly configured with minimal permissions\n5. Document all security configurations and permissions\n6. Implement proper secret management for any credentials\n7. Set up monitoring for Crossplane components",
            "status": "done",
            "testStrategy": "Perform security scanning of the cluster configuration. Verify each provider can only access resources it needs to manage and nothing more. Test by attempting to create resources outside the intended scope and confirm these operations fail."
          }
        ]
      },
      {
        "id": 12,
        "title": "Configure Karpenter for Dynamic Node Provisioning",
        "description": "Set up Karpenter in the management cluster with appropriate provisioners, taints, and tolerations to support dynamic provisioning of nodes for vCluster workloads.",
        "details": "Install Karpenter v0.30.0+ with the following configuration:\n\n1. Create dedicated node templates for vCluster workloads with taints\n2. Configure provisioners with low scale-up delay (< 10s) to minimize cold start issues\n3. Set up appropriate instance types optimized for cost/performance\n\n```yaml\n# Karpenter Provisioner for vCluster workloads\napiVersion: karpenter.sh/v1alpha5\nkind: Provisioner\nmetadata:\n  name: vcluster-provisioner\nspec:\n  requirements:\n    - key: karpenter.sh/capacity-type\n      operator: In\n      values: [\"spot\", \"on-demand\"]\n    - key: node.kubernetes.io/instance-type\n      operator: In\n      values: [\"t3a.medium\", \"t3a.large\", \"m5a.large\"]\n  taints:\n    - key: workload-type\n      value: vcluster\n      effect: NoSchedule\n  limits:\n    resources:\n      cpu: 1000\n      memory: 1000Gi\n  providerRef:\n    name: default\n  ttlSecondsAfterEmpty: 30\n  ttlSecondsUntilExpired: 2592000 # 30 days\n  startupTaints:\n    - key: node.kubernetes.io/not-ready\n      effect: NoSchedule\n  consolidation:\n    enabled: true\n```\n\nImplement node template with appropriate security groups, IAM roles, and subnet configuration. Configure Karpenter to use interruption handling for Spot instances to improve reliability.",
        "testStrategy": "1. Deploy a test pod with the vCluster taint toleration and verify Karpenter provisions a new node\n2. Test scale-down by removing workloads and verifying node termination\n3. Measure node provisioning latency to ensure it meets cold-start requirements (<30s)\n4. Verify proper instance type selection based on workload requirements\n5. Test interruption handling by simulating a spot instance interruption",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Install Karpenter v0.30.0+ in the management cluster",
            "description": "Install Karpenter v0.30.0+ in the management cluster using Helm and configure the necessary AWS infrastructure components.",
            "dependencies": [],
            "details": "1. Create necessary IAM roles for Karpenter with appropriate permissions for EC2 instance management\n2. Set up IRSA (IAM Roles for Service Accounts) for Karpenter\n3. Install Karpenter using Helm chart version 0.30.0 or newer\n4. Configure Karpenter controller with appropriate AWS region and cluster name\n5. Verify Karpenter installation by checking pods and controller logs",
            "status": "done",
            "testStrategy": "Verify Karpenter installation by checking that all Karpenter pods are running and the controller logs show successful initialization without errors."
          },
          {
            "id": 2,
            "title": "Create node template with security groups and IAM configuration",
            "description": "Create a node template for Karpenter that includes the necessary security groups, IAM roles, and subnet configuration for vCluster workloads.",
            "dependencies": [
              1
            ],
            "details": "1. Create an EC2 NodeClass or equivalent resource defining the node template\n2. Configure security groups that allow necessary network traffic for vCluster workloads\n3. Set up IAM instance profile with permissions for node operations\n4. Configure subnet selection to use private subnets in multiple availability zones\n5. Set up appropriate user data for node bootstrap process\n6. Configure instance metadata service (IMDSv2) for security",
            "status": "done",
            "testStrategy": "Validate the node template configuration by running a dry-run provisioning test and checking that the template parameters are correctly applied."
          },
          {
            "id": 3,
            "title": "Configure vCluster provisioner with taints and instance types",
            "description": "Create the Karpenter provisioner for vCluster workloads with appropriate taints, instance types, and capacity settings as specified in the requirements.",
            "dependencies": [
              2
            ],
            "details": "1. Create the vcluster-provisioner resource as specified in the YAML template\n2. Configure the instance types (t3a.medium, t3a.large, m5a.large) optimized for cost/performance\n3. Set up taints with key 'workload-type', value 'vcluster', and effect 'NoSchedule'\n4. Configure resource limits (CPU: 1000, Memory: 1000Gi)\n5. Set ttlSecondsAfterEmpty to 30 and ttlSecondsUntilExpired to 2592000 (30 days)\n6. Enable consolidation for cost optimization",
            "status": "done",
            "testStrategy": "Test the provisioner by deploying a sample workload with matching tolerations and verify that Karpenter provisions a node with the correct specifications and taints."
          },
          {
            "id": 4,
            "title": "Implement Spot instance interruption handling",
            "description": "Configure Karpenter to handle Spot instance interruptions gracefully to improve reliability of vCluster workloads running on Spot instances.",
            "dependencies": [
              3
            ],
            "details": "1. Enable the AWS Node Termination Handler or Karpenter's built-in interruption handling\n2. Configure appropriate draining behavior for Spot instances receiving interruption notices\n3. Set up event handling for EC2 Spot Instance Interruption Warning events\n4. Implement graceful pod termination with appropriate termination grace periods\n5. Configure Karpenter to quickly provision replacement capacity when interruptions occur\n6. Set up monitoring and alerting for Spot instance interruptions",
            "status": "done",
            "testStrategy": "Simulate a Spot instance interruption using AWS CLI or test tools and verify that workloads are properly drained and rescheduled to new nodes."
          },
          {
            "id": 5,
            "title": "Optimize Karpenter for fast scale-up and minimal cold start",
            "description": "Fine-tune Karpenter configuration to minimize scale-up delay and cold start issues for vCluster workloads.",
            "dependencies": [
              3,
              4
            ],
            "details": "1. Configure provisioner with low scale-up delay (< 10s) as required\n2. Implement appropriate node initialization and readiness settings\n3. Configure kubelet startup parameters for faster node registration\n4. Set up node warm pools if necessary for critical workloads\n5. Implement monitoring for scale-up events and latency\n6. Document the configuration and performance characteristics for the team",
            "status": "done",
            "testStrategy": "Measure the time from pod scheduling request to pod running state for various workload types to verify that the scale-up delay is consistently under 10 seconds."
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement VClusterEnvironmentClaim CRD and Composition",
        "description": "Create the VClusterEnvironmentClaim CRD and Crossplane Composition to provision isolated vClusters with Istio ingress and optional components (ArgoCD, observability stack).",
        "details": "1. Define the VClusterEnvironmentClaim CRD with the schema specified in the PRD\n2. Create a Crossplane Composition that provisions:\n   - vCluster using Helm chart (v0.15.0+)\n   - Istio ingress (v1.18+) with Gateway\n   - Optional components based on the 'include' field\n\n```yaml\n# VClusterEnvironmentClaim XRD\napiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: xvclusterenvironmentclaims.platform.example.org\nspec:\n  group: platform.example.org\n  names:\n    kind: XVClusterEnvironmentClaim\n    plural: xvclusterenvironmentclaims\n  claimNames:\n    kind: VClusterEnvironmentClaim\n    plural: vclusterenvironmentclaims\n  versions:\n    - name: v1alpha1\n      served: true\n      referenceable: true\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n              properties:\n                name:\n                  type: string\n                domain:\n                  type: string\n                  nullable: true\n                include:\n                  type: array\n                  items:\n                    type: string\n                    enum: [argoCD, grafana, prometheus, jaeger, kiali, apiGatewaySupport]\n              required: [name]\n```\n\nImplement the Composition to use Helm provider for vCluster and component installation. Use Kubernetes provider for namespace creation and service account setup. Configure Istio Gateway with proper domain settings if provided.",
        "testStrategy": "1. Apply the VClusterEnvironmentClaim CRD and verify it's accepted\n2. Create a test claim with minimal configuration and verify vCluster is provisioned\n3. Test with various 'include' combinations to ensure optional components are correctly installed\n4. Verify Istio ingress is properly configured and accessible\n5. Test domain configuration if provided\n6. Validate that vCluster is running on nodes with appropriate taints/tolerations",
        "priority": "high",
        "dependencies": [
          11,
          12
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define VClusterEnvironmentClaim XRD",
            "description": "Create the CompositeResourceDefinition (XRD) for VClusterEnvironmentClaim with the schema specified in the PRD",
            "dependencies": [],
            "details": "1. Create a YAML file for the XRD as shown in the PRD\n2. Add validation for the 'name' field (must be DNS-1123 compliant)\n3. Add description fields to document each property\n4. Define status subresource with appropriate fields (ready, clusterEndpoint, adminCredentials)\n5. Apply the XRD to the cluster using kubectl",
            "status": "done",
            "testStrategy": "Verify the CRD is properly registered in the cluster with 'kubectl get crds' and validate the schema with a test claim"
          },
          {
            "id": 2,
            "title": "Create base Composition for vCluster provisioning",
            "description": "Implement the core Composition that provisions a vCluster using the Helm provider",
            "dependencies": [
              1
            ],
            "details": "1. Create a Composition YAML file targeting the XRD\n2. Define resources for namespace creation\n3. Configure the Helm Release resource for vCluster v0.15.0+\n4. Set up proper values for the Helm chart (storage, service type, etc.)\n5. Define patches to propagate the name from claim to resources\n6. Configure readiness checks for the vCluster deployment",
            "status": "done",
            "testStrategy": "Deploy a basic VClusterEnvironmentClaim and verify the vCluster is provisioned correctly and accessible"
          },
          {
            "id": 3,
            "title": "Add Istio ingress with Gateway configuration",
            "description": "Extend the Composition to install Istio ingress and configure Gateway resources",
            "dependencies": [
              2
            ],
            "details": "1. Add Helm Release resource for Istio installation (v1.18+)\n2. Configure Istio Gateway resource with proper domain settings\n3. Create patches to use the domain from the claim if provided, or generate a default domain\n4. Set up Virtual Service to route traffic to the vCluster\n5. Configure TLS settings for secure access\n6. Add status patch to expose the ingress endpoint",
            "status": "done",
            "testStrategy": "Test the ingress by accessing the vCluster API through the Gateway and verify TLS is working correctly"
          },
          {
            "id": 4,
            "title": "Implement optional components installation logic",
            "description": "Add support for installing optional components based on the 'include' field",
            "dependencies": [
              3
            ],
            "details": "1. Create conditional resources for each optional component (argoCD, grafana, prometheus, jaeger, kiali, apiGatewaySupport)\n2. Configure Helm Release resources for each component with appropriate versions\n3. Implement patches to conditionally include resources based on the 'include' array\n4. Set up dependencies between components (e.g., Grafana depends on Prometheus)\n5. Configure each component to work within the vCluster environment",
            "status": "done",
            "testStrategy": "Create claims with different combinations of optional components and verify they are correctly installed and configured"
          },
          {
            "id": 5,
            "title": "Implement status updates and credential management",
            "description": "Configure the Composition to update status fields and manage admin credentials",
            "dependencies": [
              4
            ],
            "details": "1. Add patches to update the status.ready field based on all resources being ready\n2. Configure credential extraction from the vCluster secret\n3. Set up patches to populate status.adminCredentials with access information\n4. Add status.clusterEndpoint with connection details for both direct and ingress access\n5. Implement proper error handling for status updates\n6. Add connection instructions in a user-friendly format",
            "status": "done",
            "testStrategy": "Verify status fields are correctly populated after provisioning and credentials can be used to access the vCluster"
          }
        ]
      },
      {
        "id": 14,
        "title": "Set Up External Secrets Operator for Auth0 and Neon Postgres",
        "description": "Install and configure External Secrets Operator to sync Auth0 and Neon Postgres credentials (found in crossplane/application.properties) into vClusters for application use.",
        "details": "1. Install External Secrets Operator v0.9.0+ in the management cluster\n2. Configure SecretStore with AWS Secrets Manager or other backend\n3. Create ExternalSecret templates for Auth0 and Neon Postgres\n4. Implement ClusterSecretStore for cross-namespace secret access\n\n```yaml\n# Install External Secrets Operator\nhelm repo add external-secrets https://charts.external-secrets.io\nhelm install external-secrets external-secrets/external-secrets \\\n  --namespace external-secrets --create-namespace --version 0.9.0\n\n# ClusterSecretStore configuration for AWS Secrets Manager\napiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: aws-secretsmanager\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-west-2\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets-sa\n            namespace: external-secrets\n\n# ExternalSecret template for Auth0\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: auth0-credentials\n  namespace: {{.vcluster.namespace}}\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    kind: ClusterSecretStore\n    name: aws-secretsmanager\n  target:\n    name: auth0-credentials\n    creationPolicy: Owner\n  data:\n  - secretKey: clientId\n    remoteRef:\n      key: auth0/credentials\n      property: clientId\n  - secretKey: clientSecret\n    remoteRef:\n      key: auth0/credentials\n      property: clientSecret\n  - secretKey: domain\n    remoteRef:\n      key: auth0/credentials\n      property: domain\n```\n\nImplement a controller or use ArgoCD ApplicationSet to automatically create ExternalSecret resources in each vCluster namespace. Configure proper RBAC to ensure secrets are only accessible to authorized services.",
        "testStrategy": "1. Verify External Secrets Operator installation\n2. Test secret synchronization from backend to Kubernetes Secret\n3. Validate secret format matches the required schema in the PRD\n4. Test secret access from a pod in the vCluster namespace\n5. Verify secret rotation works when backend secret is updated\n6. Test error handling when backend is temporarily unavailable",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Install External Secrets Operator in Management Cluster",
            "description": "Set up External Secrets Operator v0.9.0+ in the management Kubernetes cluster to enable secret synchronization from external sources.",
            "dependencies": [],
            "details": "Use Helm to install External Secrets Operator in a dedicated namespace:\n1. Add the external-secrets Helm repository\n2. Install the operator with version 0.9.0 or newer in the 'external-secrets' namespace\n3. Verify the installation by checking that all pods are running\n4. Create a service account with appropriate permissions for accessing AWS Secrets Manager",
            "status": "done",
            "testStrategy": "Verify installation by checking pod status with 'kubectl get pods -n external-secrets' and ensure all components are in Running state. Test basic functionality by creating a simple ExternalSecret resource."
          },
          {
            "id": 2,
            "title": "Configure AWS Secrets Manager Integration",
            "description": "Set up the ClusterSecretStore resource to connect External Secrets Operator with AWS Secrets Manager where Auth0 and Neon Postgres credentials are stored.",
            "dependencies": [
              1
            ],
            "details": "1. Create an IAM role with permissions to access the required AWS Secrets Manager secrets\n2. Configure IRSA (IAM Roles for Service Accounts) for the external-secrets service account\n3. Create a ClusterSecretStore resource that references the service account and specifies AWS region\n4. Test the connection to ensure the operator can retrieve secrets from AWS Secrets Manager\n5. Document the AWS secret path structure for Auth0 and Neon credentials",
            "status": "done",
            "testStrategy": "Create a test ExternalSecret that references a known AWS secret and verify it successfully syncs to a Kubernetes Secret. Check logs for any authentication or permission errors."
          },
          {
            "id": 3,
            "title": "Create ExternalSecret Templates for Auth0 and Neon Postgres",
            "description": "Develop template manifests for ExternalSecret resources that will sync Auth0 and Neon Postgres credentials from AWS Secrets Manager to Kubernetes Secrets in vCluster namespaces.",
            "dependencies": [
              2
            ],
            "details": "1. Analyze the structure of Auth0 and Neon Postgres credentials in AWS Secrets Manager\n2. Create an ExternalSecret template for Auth0 with appropriate secretKey and remoteRef mappings\n3. Create an ExternalSecret template for Neon Postgres with appropriate secretKey and remoteRef mappings\n4. Include namespace templating to allow deployment across multiple vClusters\n5. Set appropriate refresh intervals and creation policies\n6. Ensure secret naming conventions align with application expectations",
            "status": "done",
            "testStrategy": "Deploy the templates manually to a test namespace and verify that the correct secret data is synchronized. Check that applications can successfully use the secrets."
          },
          {
            "id": 4,
            "title": "Implement Automated ExternalSecret Deployment",
            "description": "Create a mechanism to automatically deploy ExternalSecret resources to each vCluster namespace using either a custom controller or ArgoCD ApplicationSet.",
            "dependencies": [
              3
            ],
            "details": "1. Evaluate whether to use a custom controller or ArgoCD ApplicationSet based on existing infrastructure\n2. If using ArgoCD:\n   - Create an ApplicationSet template that generates Applications for each vCluster\n   - Configure the template to deploy ExternalSecret resources with appropriate namespace substitution\n3. If using a custom controller:\n   - Develop a controller that watches for vCluster creation\n   - Automatically deploy ExternalSecret resources when new vClusters are detected\n4. Implement error handling and logging for deployment failures\n5. Add annotations to track which controller created each ExternalSecret",
            "status": "done",
            "testStrategy": "Test by creating a new vCluster and verifying that ExternalSecret resources are automatically deployed. Verify that updates to templates propagate correctly to existing deployments."
          },
          {
            "id": 5,
            "title": "Configure RBAC and Validate End-to-End Functionality",
            "description": "Set up appropriate RBAC permissions to secure access to secrets and validate the entire secret synchronization process from AWS to applications running in vClusters.",
            "dependencies": [
              4
            ],
            "details": "1. Create Role and RoleBinding resources to restrict access to secrets within each vCluster namespace\n2. Configure NetworkPolicies to limit which pods can access the Kubernetes API for secret retrieval\n3. Implement PodSecurityPolicies or Pod Security Standards to prevent privilege escalation\n4. Perform end-to-end testing with actual application deployments in vClusters\n5. Document the entire setup including troubleshooting steps for common issues\n6. Create monitoring alerts for secret synchronization failures",
            "status": "done",
            "testStrategy": "Deploy a test application that requires Auth0 and Neon Postgres credentials. Verify the application can successfully authenticate with both services using the synchronized secrets. Test secret rotation by updating values in AWS Secrets Manager and confirming they propagate correctly."
          }
        ]
      },
      {
        "id": 15,
        "title": "Implement ApplicationClaim CRD and Composition",
        "description": "Create the ApplicationClaim CRD and Crossplane Composition to provision application resources including GitHub repo, CI/CD pipeline, Knative service, and dependencies.",
        "details": "1. Define the ApplicationClaim CRD with the schema specified in the PRD\n2. Create a Crossplane Composition that provisions:\n   - GitHub repository with appropriate template based on language/framework\n   - GitHub Actions workflow for CI/CD to Docker Hub\n   - Knative Service via OAM components\n   - ArgoCD Application for GitOps\n   - Database and cache if specified\n\n```yaml\n# ApplicationClaim XRD\napiVersion: apiextensions.crossplane.io/v1\nkind: CompositeResourceDefinition\nmetadata:\n  name: xapplicationclaims.platform.example.org\nspec:\n  group: platform.example.org\n  names:\n    kind: XApplicationClaim\n    plural: xapplicationclaims\n  claimNames:\n    kind: ApplicationClaim\n    plural: applicationclaims\n  versions:\n    - name: v1alpha1\n      served: true\n      referenceable: true\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n              properties:\n                name:\n                  type: string\n                language:\n                  type: string\n                  enum: [python, java]\n                framework:\n                  type: string\n                  enum: [fastapi, springboot]\n                hasFrontend:\n                  type: boolean\n                database:\n                  type: string\n                  enum: [postgres, none]\n                cache:\n                  type: string\n                  enum: [redis, none]\n                exposeApi:\n                  type: boolean\n              required: [name, language, framework]\n```\n\nImplement template repositories for each language/framework combination with proper Dockerfile, CI/CD workflow, and application structure. Use GitHub provider to create repositories and configure webhooks. Create OAM Component and Application definitions for Knative services.",
        "testStrategy": "1. Apply the ApplicationClaim CRD and verify it's accepted\n2. Create a test claim for each language/framework combination\n3. Verify GitHub repository is created with correct template\n4. Test CI/CD pipeline by making a code change\n5. Verify Knative service is deployed and accessible\n6. Test database and cache provisioning if specified\n7. Validate that secrets are properly injected into the application",
        "priority": "high",
        "dependencies": [
          11,
          14
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define and implement ApplicationClaim CRD",
            "description": "Create the ApplicationClaim Custom Resource Definition (CRD) based on the schema provided in the PRD, ensuring all required fields and validations are properly implemented.",
            "dependencies": [],
            "details": "1. Create the CompositeResourceDefinition (XRD) YAML file for ApplicationClaim as specified in the PRD\n2. Ensure proper validation for enum fields (language, framework, database, cache)\n3. Add defaulting logic where appropriate (e.g., hasFrontend=false, database=none, cache=none if not specified)\n4. Include proper descriptions for each field to aid users\n5. Apply the CRD to the cluster and verify it can be created",
            "status": "done",
            "testStrategy": "Create test ApplicationClaim resources with various combinations of parameters to verify schema validation works correctly. Use kubectl explain to verify field documentation."
          },
          {
            "id": 2,
            "title": "Create template repositories for supported language/framework combinations",
            "description": "Implement template GitHub repositories for each supported language and framework combination that will be used as the basis for new application repositories.",
            "dependencies": [],
            "details": "1. Create template repositories for: python-fastapi, java-springboot\n2. Each template should include:\n   - Appropriate Dockerfile optimized for the language/framework\n   - GitHub Actions workflow for CI/CD to Docker Hub\n   - Basic application structure with health endpoints\n   - README with usage instructions\n   - Configuration for database and cache connections (if applicable)\n3. Implement conditional logic in templates to handle optional features (frontend, database, cache, API exposure)",
            "status": "done",
            "testStrategy": "Build and run each template locally to verify it works. Test the CI/CD workflow by making a sample commit."
          },
          {
            "id": 3,
            "title": "Implement Crossplane Composition for GitHub resources",
            "description": "Create the first part of the Crossplane Composition that handles GitHub repository creation and configuration based on ApplicationClaim parameters.",
            "dependencies": [
              1,
              2
            ],
            "details": "1. Create a Composition that references the ApplicationClaim XRD\n2. Implement composition resources for GitHub provider to:\n   - Create a new repository with name from the claim\n   - Select and apply the appropriate template based on language/framework\n   - Configure branch protection rules\n   - Set up webhooks for CI/CD integration\n3. Include proper patching to pass parameters from the claim to the composed resources\n4. Handle error cases and provide meaningful status updates",
            "status": "done",
            "testStrategy": "Create test ApplicationClaims and verify that GitHub repositories are created with the correct template and configuration."
          },
          {
            "id": 4,
            "title": "Implement Crossplane Composition for infrastructure resources",
            "description": "Extend the Composition to provision infrastructure resources like databases and caches when specified in the ApplicationClaim.",
            "dependencies": [
              3
            ],
            "details": "1. Add composition resources for database provisioning when database=postgres\n   - Create a PostgreSQL instance or claim an existing one\n   - Generate and store connection credentials securely\n2. Add composition resources for cache provisioning when cache=redis\n   - Create a Redis instance or claim an existing one\n   - Generate and store connection information\n3. Implement proper dependency chains between resources\n4. Configure connection information to be injected into the application deployment",
            "status": "done",
            "testStrategy": "Create ApplicationClaims with different database and cache configurations and verify the correct resources are provisioned with proper credentials."
          },
          {
            "id": 5,
            "title": "Implement Crossplane Composition for Knative and ArgoCD resources",
            "description": "Complete the Composition by adding resources for deploying the application using Knative and ArgoCD for GitOps-based continuous deployment.",
            "dependencies": [
              3,
              4
            ],
            "details": "1. Add composition resources to create OAM Component definitions for Knative services\n   - Configure scaling parameters based on application type\n   - Set up proper container configuration with environment variables\n   - Configure networking based on exposeApi parameter\n2. Create ArgoCD Application resource that points to the GitHub repository\n   - Configure sync policy for automatic deployment\n   - Set up appropriate health checks\n3. Implement status reporting from all composed resources back to the ApplicationClaim\n4. Add finalizers to handle proper cleanup of all resources when an ApplicationClaim is deleted",
            "status": "done",
            "testStrategy": "Create end-to-end tests that verify a complete ApplicationClaim results in a running application with all supporting infrastructure. Test deletion to ensure proper cleanup."
          },
          {
            "id": 6,
            "title": "Define ApplicationClaim CRD and XRD",
            "description": "Create the ApplicationClaim Custom Resource Definition (CRD) and Composite Resource Definition (XRD) with the schema specified in the PRD.",
            "dependencies": [],
            "details": "1. Create the CompositeResourceDefinition (XRD) YAML file as specified in the PRD\n2. Ensure all required fields (name, language, framework) are properly defined\n3. Add validation for enum fields (language, framework, database, cache)\n4. Define the claim mapping with appropriate claimNames\n5. Add defaulting where appropriate\n6. Document the CRD schema for platform users",
            "status": "done",
            "testStrategy": "Validate the CRD using kubectl explain and create test instances to verify schema validation works correctly."
          },
          {
            "id": 7,
            "title": "Create template repositories for language/framework combinations",
            "description": "Implement template repositories for each supported language/framework combination with proper application structure, Dockerfile, and basic configuration.",
            "dependencies": [
              6
            ],
            "details": "1. Create template repositories for:\n   - Python/FastAPI\n   - Java/SpringBoot\n2. Each template should include:\n   - Appropriate project structure\n   - Dockerfile optimized for the language/framework\n   - README with usage instructions\n   - Basic application code with health endpoints\n   - Configuration for environment variables\n3. Ensure templates can be easily cloned and customized",
            "status": "done",
            "testStrategy": "Build and run each template locally to verify it works correctly. Test the Dockerfile builds and runs the application properly."
          },
          {
            "id": 8,
            "title": "Implement GitHub repository provisioning in Composition",
            "description": "Create the Crossplane Composition component that provisions GitHub repositories based on the ApplicationClaim parameters.",
            "dependencies": [
              7
            ],
            "details": "1. Define the Composition resource that references the XRD\n2. Add a ComposedResource for GitHub repository creation\n3. Implement template selection logic based on language/framework\n4. Configure repository settings (visibility, branch protection)\n5. Set up appropriate permissions for the repository\n6. Implement patch transformations to map from claim fields to provider fields",
            "status": "done",
            "testStrategy": "Create test ApplicationClaims and verify that repositories are created with correct settings and template content."
          },
          {
            "id": 9,
            "title": "Implement CI/CD workflow and Knative service provisioning",
            "description": "Extend the Composition to provision CI/CD workflows (GitHub Actions) and Knative service resources.",
            "dependencies": [
              8
            ],
            "details": "1. Add ComposedResource for GitHub Actions workflow configuration\n2. Configure workflow to build and push to Docker Hub\n3. Add ComposedResource for Knative Service via OAM components\n4. Implement conditional logic for frontend/API exposure based on claim parameters\n5. Configure appropriate scaling parameters for Knative\n6. Set up environment variables and secrets management\n7. Implement ArgoCD Application resource for GitOps deployment",
            "status": "done",
            "testStrategy": "Test the end-to-end workflow by creating an ApplicationClaim and verifying that CI/CD is triggered correctly and the Knative service is deployed."
          },
          {
            "id": 10,
            "title": "Implement database and cache provisioning",
            "description": "Complete the Composition by adding optional database and cache provisioning based on ApplicationClaim parameters.",
            "dependencies": [
              9
            ],
            "details": "1. Add ComposedResources for database (PostgreSQL) when specified\n2. Add ComposedResources for cache (Redis) when specified\n3. Implement connection string and credential management\n4. Configure appropriate resource limits and scaling parameters\n5. Set up backup and recovery options\n6. Inject connection details into the application environment\n7. Document the complete ApplicationClaim usage with examples for different configurations",
            "status": "done",
            "testStrategy": "Create ApplicationClaims with different database and cache configurations and verify that resources are provisioned correctly and applications can connect to them."
          }
        ]
      },
      {
        "id": 16,
        "title": "Configure Knative Serving with Cold Start Protection",
        "description": "Install and configure Knative Serving with optimized settings for cold start protection, including concurrency state endpoint and appropriate scaling parameters.",
        "details": "1. Install Knative Serving v1.11.0+ in the management cluster\n2. Configure Activator with concurrency-state-endpoint\n3. Set up default autoscaling parameters for minimal cold start impact\n4. Create custom ConfigMap for Knative defaults\n\n```yaml\n# Install Knative Serving\nkubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.11.0/serving-crds.yaml\nkubectl apply -f https://github.com/knative/serving/releases/download/knative-v1.11.0/serving-core.yaml\n\n# Configure Knative for cold start protection\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: config-autoscaler\n  namespace: knative-serving\ndata:\n  enable-scale-to-zero: \"true\"\n  scale-to-zero-grace-period: \"30s\"\n  scale-to-zero-pod-retention-period: \"1m\"\n  min-scale: \"1\"\n  max-scale-up-rate: \"10.0\"\n  max-scale-down-rate: \"2.0\"\n  panic-window-percentage: \"10.0\"\n  panic-threshold-percentage: \"200.0\"\n  stable-window: \"60s\"\n  target-burst-capacity: \"200\"\n  container-concurrency-target-percentage: \"70\"\n  container-concurrency-target-default: \"100\"\n  activator-capacity: \"100\"\n  initial-scale: \"1\"\n  allow-zero-initial-scale: \"false\"\n  max-scale: \"10\"\n  concurrency-state-endpoint: \"/healthz/concurrency\"\n```\n\nImplement a default Knative Service template with appropriate annotations for autoscaling and concurrency. Create a pre-warming logic for latency-sensitive applications using a CronJob that sends periodic requests to keep services warm.",
        "testStrategy": "1. Verify Knative Serving installation\n2. Test scale-to-zero and scale-from-zero behavior\n3. Measure cold start latency with and without concurrency-state-endpoint\n4. Test pre-warming logic for latency-sensitive applications\n5. Verify that no requests are lost during scale-up events\n6. Load test to ensure proper scaling under high concurrency",
        "priority": "high",
        "dependencies": [
          11
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Install Knative Serving in the management cluster",
            "description": "Install Knative Serving v1.11.0+ in the management cluster by applying the necessary YAML manifests for CRDs and core components.",
            "dependencies": [],
            "details": "Use kubectl to apply the Knative Serving CRDs and core components from the official GitHub repository. Verify the installation by checking that all pods in the knative-serving namespace are running. Ensure that the Knative API resources are available by running 'kubectl api-resources | grep knative'.",
            "status": "done",
            "testStrategy": "Verify installation by checking pod status with 'kubectl get pods -n knative-serving' and ensure all pods are in Running state. Test the API availability with 'kubectl get ksvc' to confirm no errors."
          },
          {
            "id": 2,
            "title": "Configure Knative Autoscaler with cold start protection settings",
            "description": "Create and apply a ConfigMap for the Knative Autoscaler with optimized settings for cold start protection, including scale-to-zero parameters and concurrency settings.",
            "dependencies": [
              1
            ],
            "details": "Create a ConfigMap named 'config-autoscaler' in the knative-serving namespace with the specified parameters for cold start protection. Key settings include: scale-to-zero-grace-period, min-scale, initial-scale, container-concurrency targets, and the concurrency-state-endpoint set to '/healthz/concurrency'. Apply the ConfigMap and verify it's correctly configured.",
            "status": "done",
            "testStrategy": "Verify the ConfigMap exists and has the correct values with 'kubectl get configmap config-autoscaler -n knative-serving -o yaml'. Test that the settings are applied by deploying a test service and observing its scaling behavior."
          },
          {
            "id": 3,
            "title": "Implement default Knative Service template with autoscaling annotations",
            "description": "Create a default Knative Service template with appropriate annotations for autoscaling and concurrency to be used as a reference for all services.",
            "dependencies": [
              2
            ],
            "details": "Develop a YAML template for Knative Services that includes annotations for autoscaling such as 'autoscaling.knative.dev/minScale', 'autoscaling.knative.dev/target', and 'autoscaling.knative.dev/metric'. The template should set appropriate defaults for concurrency and include the health check endpoint that matches the concurrency-state-endpoint. Document the template and its annotations for team reference.",
            "status": "done",
            "testStrategy": "Deploy a test service using the template and verify that the annotations are correctly applied with 'kubectl get ksvc <service-name> -o yaml'. Test scaling behavior by generating load and observing that the service scales according to the configured parameters."
          },
          {
            "id": 4,
            "title": "Develop pre-warming logic using CronJob for latency-sensitive applications",
            "description": "Create a CronJob that sends periodic requests to keep latency-sensitive Knative services warm, preventing cold starts during periods of inactivity.",
            "dependencies": [
              3
            ],
            "details": "Implement a Kubernetes CronJob that periodically sends HTTP requests to specified Knative services. The CronJob should use a simple container with curl or a similar tool to make requests to the service endpoints. Configure the schedule based on the scale-to-zero-grace-period to ensure services remain warm. Include logic to identify which services need warming based on labels or annotations.",
            "status": "done",
            "testStrategy": "Deploy the CronJob and monitor its execution with 'kubectl get cronjobs' and 'kubectl logs'. Verify that targeted services remain warm by checking their pod count doesn't drop to zero with 'kubectl get pods' and by measuring response times to confirm no cold start delays."
          },
          {
            "id": 5,
            "title": "Create documentation and monitoring for cold start performance",
            "description": "Document the Knative cold start protection configuration and implement monitoring to track cold start performance metrics.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Create comprehensive documentation explaining the cold start protection strategy, including the ConfigMap settings, service template annotations, and pre-warming mechanism. Implement Prometheus metrics collection for Knative services, focusing on activation time, request latencies, and concurrency. Set up Grafana dashboards to visualize these metrics and configure alerts for cold start issues.",
            "status": "done",
            "testStrategy": "Review documentation with team members to ensure clarity. Verify metrics collection by intentionally triggering cold starts and confirming the metrics are captured in Prometheus. Test alerts by simulating conditions that would trigger them."
          }
        ]
      },
      {
        "id": 17,
        "title": "Implement AWS API Gateway Integration for Service Exposure",
        "description": "Create the infrastructure to automatically provision AWS API Gateway endpoints for applications with exposeApi: true, including VPC Link for internal services.",
        "details": "1. Create a Crossplane Composition for AWS API Gateway resources\n2. Implement logic to detect 'exposeApi: true' in ApplicationClaim\n3. Configure VPC Link for internal services\n4. Set up public routes for external services\n\n```yaml\n# AWS API Gateway Composition\napiVersion: apiextensions.crossplane.io/v1\nkind: Composition\nmetadata:\n  name: apigateway.platform.example.org\nspec:\n  compositeTypeRef:\n    apiVersion: platform.example.org/v1alpha1\n    kind: XApiGateway\n  resources:\n    - name: apigateway\n      base:\n        apiVersion: apigateway.aws.crossplane.io/v1alpha1\n        kind: RestAPI\n        spec:\n          forProvider:\n            region: us-west-2\n            name: \"{{.parameters.name}}-api\"\n            description: \"API Gateway for {{.parameters.name}}\"\n            endpointConfiguration:\n              types: [REGIONAL]\n            apiKeySource: HEADER\n          providerConfigRef:\n            name: aws-provider\n    - name: vpclink\n      base:\n        apiVersion: apigateway.aws.crossplane.io/v1alpha1\n        kind: VpcLink\n        spec:\n          forProvider:\n            region: us-west-2\n            name: \"{{.parameters.name}}-vpclink\"\n            targetArns: [\"{{.parameters.nlbArn}}\"] # NLB ARN for internal services\n          providerConfigRef:\n            name: aws-provider\n```\n\nImplement a controller or webhook that watches for ApplicationClaim resources with exposeApi: true and creates the necessary API Gateway resources. Configure proper IAM permissions for API Gateway to access the VPC Link and NLB.",
        "testStrategy": "1. Create an ApplicationClaim with exposeApi: true\n2. Verify API Gateway is provisioned\n3. Test internal service access via VPC Link\n4. Test public route access\n5. Verify proper authentication and authorization\n6. Test error handling and retry logic\n7. Validate that API Gateway is properly integrated with the Knative service",
        "priority": "medium",
        "dependencies": [
          15,
          16
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create XApiGateway CRD and Composition",
            "description": "Define the XApiGateway Custom Resource Definition and complete the Composition for AWS API Gateway resources including VPC Link integration.",
            "dependencies": [],
            "details": "1. Create the XApiGateway CRD with appropriate fields (name, namespace, exposeApi flag, nlbArn, etc.)\n2. Complete the Composition template with all necessary resources (RestAPI, VpcLink, Resources, Methods, Integrations)\n3. Add support for both internal (VPC Link) and external (public) service exposure patterns\n4. Define proper composition parameters for dynamic configuration\n5. Include IAM role resources in the composition for API Gateway permissions",
            "status": "pending",
            "testStrategy": "Validate CRD and Composition with kubectl apply and verify they are correctly registered in the cluster. Test with a simple manual XApiGateway resource creation."
          },
          {
            "id": 2,
            "title": "Implement ApplicationClaim Controller with API Gateway Detection",
            "description": "Create a controller that watches ApplicationClaim resources and detects the 'exposeApi: true' flag to trigger API Gateway provisioning.",
            "dependencies": [
              1
            ],
            "details": "1. Create a new controller or extend existing one to watch ApplicationClaim resources\n2. Add logic to detect the 'exposeApi: true' flag in ApplicationClaim spec\n3. Extract service information (name, namespace, ports) from the ApplicationClaim\n4. Implement reconciliation logic to create or update an XApiGateway resource when needed\n5. Handle deletion of API Gateway resources when ApplicationClaim is deleted",
            "status": "pending",
            "testStrategy": "Write unit tests for the controller logic. Create test ApplicationClaim resources with and without exposeApi flag to verify detection works correctly."
          },
          {
            "id": 3,
            "title": "Implement NLB Discovery and VPC Link Configuration",
            "description": "Create logic to discover or provision Network Load Balancers for internal services and configure VPC Links to connect API Gateway to these NLBs.",
            "dependencies": [
              2
            ],
            "details": "1. Implement logic to discover existing NLBs for the service or provision new ones if needed\n2. Extract the NLB ARN and store it for use in the VPC Link configuration\n3. Configure the VPC Link with the correct NLB ARN in the XApiGateway resource\n4. Set up proper security groups and network configurations for the VPC Link\n5. Implement health checks and validation for the NLB-VPC Link connection",
            "status": "pending",
            "testStrategy": "Test with internal services running in the VPC. Verify the NLB discovery works correctly and the VPC Link is properly configured with the correct ARN."
          },
          {
            "id": 4,
            "title": "Configure API Gateway Routes and Integrations",
            "description": "Implement the logic to set up API Gateway routes, methods, and integrations based on the service endpoints.",
            "dependencies": [
              3
            ],
            "details": "1. Create Resource and Method resources in the API Gateway composition for each service endpoint\n2. Configure HTTP_PROXY integration for VPC Link (internal) services\n3. Set up direct integrations for external services\n4. Implement path mapping and route configuration based on service metadata\n5. Configure appropriate request/response mappings and transformations",
            "status": "pending",
            "testStrategy": "Test API routes with curl or Postman to verify they correctly proxy to the backend services. Verify both GET and POST methods work correctly."
          },
          {
            "id": 5,
            "title": "Implement Deployment and Stage Management",
            "description": "Create the logic to manage API Gateway deployments, stages, and provide endpoint information back to users.",
            "dependencies": [
              4
            ],
            "details": "1. Add Deployment and Stage resources to the API Gateway composition\n2. Implement logic to trigger new deployments when API configuration changes\n3. Configure stage variables and settings (logging, throttling, etc.)\n4. Update the ApplicationClaim status with the API Gateway endpoint URL\n5. Implement a mechanism to output API keys or IAM permissions if authentication is required",
            "status": "pending",
            "testStrategy": "Verify that changes to the API configuration trigger new deployments. Test the complete flow from ApplicationClaim creation to having a working API endpoint. Verify the endpoint URL is correctly reported in the ApplicationClaim status."
          }
        ]
      },
      {
        "id": 18,
        "title": "Set Up Observability Stack with Prometheus, Grafana, Jaeger, and Kiali",
        "description": "Install and configure the observability stack (Prometheus, Grafana, Jaeger, Kiali) for monitoring and tracing of vCluster environments and applications.",
        "details": "1. Create Helm charts or Kustomize manifests for each component\n2. Configure Prometheus with appropriate scrape configs for Knative and Istio\n3. Set up Grafana dashboards for Kubernetes, Knative, and Istio metrics\n4. Configure Jaeger for distributed tracing\n5. Set up Kiali for service mesh visualization\n\n```yaml\n# Prometheus configuration for Knative and Istio metrics\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: monitoring\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n    scrape_configs:\n      - job_name: 'kubernetes-pods'\n        kubernetes_sd_configs:\n          - role: pod\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n            action: replace\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n            target_label: __address__\n      - job_name: 'istio-mesh'\n        kubernetes_sd_configs:\n          - role: pod\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_label_app]\n            action: keep\n            regex: istio-mesh\n```\n\nImplement a modular approach where components can be enabled/disabled based on the 'include' field in VClusterEnvironmentClaim. Configure proper resource limits and requests for each component to ensure stability.",
        "testStrategy": "1. Verify installation of each component\n2. Test metric collection from Knative and Istio\n3. Validate Grafana dashboards for visibility into key metrics\n4. Test distributed tracing with Jaeger\n5. Verify service mesh visualization with Kiali\n6. Test resource usage and performance impact\n7. Validate that components can be enabled/disabled as specified",
        "priority": "medium",
        "dependencies": [
          13,
          16
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Helm Charts for Observability Components",
            "description": "Develop Helm charts for Prometheus, Grafana, Jaeger, and Kiali that can be conditionally installed based on the 'include' field in VClusterEnvironmentClaim.",
            "dependencies": [],
            "details": "Create a directory structure for Helm charts with separate charts for each component (prometheus, grafana, jaeger, kiali). Each chart should include templates for deployments, services, configmaps, and RBAC resources. Implement a values.yaml file for each chart with configurable resource limits/requests and other parameters. Create an umbrella chart that can conditionally enable/disable each component based on configuration values.",
            "status": "pending",
            "testStrategy": "Validate each chart with 'helm lint' and 'helm template'. Test installation in a development environment with different combinations of enabled/disabled components."
          },
          {
            "id": 2,
            "title": "Configure Prometheus with Scrape Configs for Knative and Istio",
            "description": "Set up Prometheus with appropriate scrape configurations to collect metrics from Kubernetes, Knative, and Istio components.",
            "dependencies": [],
            "details": "Extend the Prometheus Helm chart to include the provided scrape configuration for Kubernetes pods and Istio mesh. Add additional scrape configurations for Knative components (activator, autoscaler, controller). Configure appropriate relabeling rules to properly identify and categorize metrics. Set up alerting rules for critical service metrics. Ensure Prometheus has the necessary RBAC permissions to discover and scrape targets across namespaces.",
            "status": "pending",
            "testStrategy": "Verify Prometheus is successfully scraping targets by checking the targets page in the Prometheus UI. Confirm metrics are being collected by querying for known metrics from Knative and Istio components."
          },
          {
            "id": 3,
            "title": "Set Up Grafana with Dashboards for Kubernetes, Knative, and Istio",
            "description": "Configure Grafana with pre-built dashboards for visualizing metrics from Kubernetes, Knative, and Istio, and set up Prometheus as a data source.",
            "dependencies": [],
            "details": "Configure Grafana to use Prometheus as a data source in the Helm chart. Import or create dashboards for Kubernetes cluster metrics, node metrics, and pod metrics. Import or create Knative-specific dashboards for monitoring serving and eventing components. Import or create Istio dashboards for monitoring service mesh performance. Set up a default organization, users, and permissions. Configure persistent storage for Grafana to retain dashboard configurations.",
            "status": "pending",
            "testStrategy": "Verify all dashboards load correctly and display data from Prometheus. Test dashboard filtering and variable functionality. Ensure dashboards are automatically provisioned during installation."
          },
          {
            "id": 4,
            "title": "Configure Jaeger for Distributed Tracing",
            "description": "Set up Jaeger for collecting and visualizing distributed traces from applications and service mesh components.",
            "dependencies": [],
            "details": "Configure Jaeger with appropriate storage backend (start with in-memory for development, Elasticsearch for production). Set up Jaeger agent as a DaemonSet to collect traces from each node. Configure sampling strategies to balance performance and observability. Integrate Jaeger with Istio to collect traces automatically from the service mesh. Create a service and ingress/route for accessing the Jaeger UI. Configure appropriate resource limits based on expected trace volume.",
            "status": "pending",
            "testStrategy": "Generate test traces using sample applications. Verify traces are properly collected and displayed in the Jaeger UI. Test different sampling configurations to ensure appropriate trace collection."
          },
          {
            "id": 5,
            "title": "Integrate Kiali for Service Mesh Visualization and Management",
            "description": "Set up Kiali to provide visualization and management capabilities for the Istio service mesh.",
            "dependencies": [],
            "details": "Configure Kiali to use Prometheus as a metrics source. Set up integration with Jaeger for trace visualization within Kiali. Configure RBAC for Kiali to access required Kubernetes resources. Set up authentication for the Kiali dashboard (OAuth or basic auth). Create a service and ingress/route for accessing the Kiali UI. Configure Kiali to display custom application health metrics. Ensure Kiali can properly visualize the service mesh topology for vCluster environments.",
            "status": "pending",
            "testStrategy": "Verify Kiali correctly displays the service mesh topology. Test service graph generation and traffic flow visualization. Confirm integration with Jaeger by following traces from the Kiali UI."
          }
        ]
      },
      {
        "id": 19,
        "title": "Implement GitHub Actions CI/CD Templates",
        "description": "Create GitHub Actions workflow templates for Python (FastAPI) and Java (Spring Boot) applications with CI/CD pipelines to Docker Hub and GitOps updates.",
        "details": "1. Create GitHub Actions workflow templates for each language/framework\n2. Configure Docker Hub authentication and image pushing\n3. Implement GitOps updates to ArgoCD repository\n4. Set up proper testing and validation steps\n\n```yaml\n# GitHub Actions workflow for Python/FastAPI\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install pytest\n        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi\n    - name: Test with pytest\n      run: pytest\n\n  build-and-push:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n    steps:\n    - uses: actions/checkout@v3\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v2\n    - name: Login to DockerHub\n      uses: docker/login-action@v2\n      with:\n        username: ${{ secrets.DOCKERHUB_USERNAME }}\n        password: ${{ secrets.DOCKERHUB_TOKEN }}\n    - name: Build and push\n      uses: docker/build-push-action@v4\n      with:\n        context: .\n        push: true\n        tags: socrates12345/${{ github.event.repository.name }}:latest\n\n  update-gitops:\n    needs: build-and-push\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v3\n      with:\n        repository: socrates12345/gitops-repo\n        token: ${{ secrets.GITOPS_PAT }}\n    - name: Update image tag\n      run: |\n        cd apps/${{ github.event.repository.name }}\n        sed -i 's|image: socrates12345/${{ github.event.repository.name }}:.*|image: socrates12345/${{ github.event.repository.name }}:latest|' deployment.yaml\n        git config user.name github-actions\n        git config user.email github-actions@github.com\n        git add .\n        git commit -m \"Update ${{ github.event.repository.name }} image to latest\"\n        git push\n```\n\nImplement similar workflow for Java/Spring Boot with appropriate build tools (Maven/Gradle). Configure secrets for Docker Hub and GitOps repository access. Set up proper caching for dependencies to speed up builds.",
        "testStrategy": "1. Test workflow with sample Python/FastAPI application\n2. Test workflow with sample Java/Spring Boot application\n3. Verify Docker image is built and pushed to Docker Hub\n4. Validate GitOps update to ArgoCD repository\n5. Test error handling and notifications\n6. Verify that tests are run before building/pushing\n7. Test with various dependency configurations",
        "priority": "medium",
        "dependencies": [
          15
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Python/FastAPI GitHub Actions workflow template",
            "description": "Implement a complete GitHub Actions workflow template for Python/FastAPI applications with testing, Docker image building, and pushing to Docker Hub.",
            "dependencies": [],
            "details": "Create a YAML file named 'python-fastapi-workflow.yml' with jobs for testing, building Docker images, and pushing to Docker Hub. Include proper caching for pip dependencies to speed up builds. Configure the workflow to trigger on push to main branch and pull requests. Use the provided example as a starting point, but enhance it with dependency caching and multi-stage Docker builds for smaller images.",
            "status": "pending",
            "testStrategy": "Manually test the workflow by creating a sample FastAPI application and triggering the workflow. Verify that tests run, Docker image builds, and is pushed to Docker Hub correctly."
          },
          {
            "id": 2,
            "title": "Create Java/Spring Boot GitHub Actions workflow template",
            "description": "Implement a complete GitHub Actions workflow template for Java/Spring Boot applications with Maven/Gradle build, testing, Docker image building, and pushing to Docker Hub.",
            "dependencies": [],
            "details": "Create a YAML file named 'java-springboot-workflow.yml' with jobs for building with Maven/Gradle, running tests, building Docker images, and pushing to Docker Hub. Include proper caching for Maven/Gradle dependencies. Configure the workflow to use JDK 17, run unit and integration tests, and build optimized Docker images. Include both Maven and Gradle configurations with conditional execution based on which build tool is detected in the repository.",
            "status": "pending",
            "testStrategy": "Manually test the workflow by creating a sample Spring Boot application with both Maven and Gradle configurations to ensure both paths work correctly."
          },
          {
            "id": 3,
            "title": "Implement GitOps update workflow component",
            "description": "Create a reusable GitHub Actions workflow component that updates the GitOps repository with the new image tag after successful Docker image build and push.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create a YAML file named 'gitops-update.yml' that can be included in both Python and Java workflows. This component should checkout the GitOps repository, update the appropriate Kubernetes manifest files with the new image tag, commit the changes, and push them back to the repository. Configure proper authentication using GitHub Personal Access Tokens (PATs) stored as secrets. Include error handling and validation to ensure the GitOps repository is in the expected state before making changes.",
            "status": "pending",
            "testStrategy": "Test the GitOps update component with a sample GitOps repository structure. Verify that it correctly updates the deployment manifests and pushes changes."
          },
          {
            "id": 4,
            "title": "Configure secrets management and documentation",
            "description": "Set up the required secrets for Docker Hub authentication and GitOps repository access, and create comprehensive documentation for using the workflow templates.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create a README.md file explaining how to set up the required secrets in the GitHub repository: DOCKERHUB_USERNAME, DOCKERHUB_TOKEN, and GITOPS_PAT. Include step-by-step instructions for generating these tokens/credentials from Docker Hub and GitHub. Document how to configure the workflows for specific projects, including any customization options. Create a template for the GitOps repository structure that works with the update workflow.",
            "status": "pending",
            "testStrategy": "Have another team member follow the documentation to set up the workflows in a test repository to verify clarity and completeness."
          },
          {
            "id": 5,
            "title": "Implement workflow templates with matrix builds and environment deployments",
            "description": "Enhance the workflow templates to support matrix builds for multiple Python/Java versions and deployment to different environments (dev, staging, production).",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Update both workflow templates to include matrix builds that test against multiple language versions (e.g., Python 3.9, 3.10, 3.11 or Java 11, 17, 21). Add environment-specific deployment configurations that tag Docker images appropriately (e.g., :dev, :staging, :production) based on the branch or tag that triggered the workflow. Implement conditional GitOps updates that target the correct environment folder in the GitOps repository. Include proper approval gates for production deployments using GitHub environments with required reviewers.",
            "status": "pending",
            "testStrategy": "Test the enhanced workflows with a sample application, triggering builds for different branches and verifying that the correct environments are updated in the GitOps repository."
          }
        ]
      },
      {
        "id": 20,
        "title": "Create Application Templates for Python and Java",
        "description": "Develop template repositories for Python (FastAPI) and Java (Spring Boot) applications with proper structure, Dockerfile, configuration, and integration with Auth0 and Neon Postgres.",
        "details": "1. Create template repositories for each language/framework\n2. Implement proper Dockerfile with multi-stage builds\n3. Configure Auth0 integration\n4. Set up Neon Postgres connection\n5. Implement health checks and metrics endpoints\n\n**Python/FastAPI Template:**\n```python\n# main.py\nfrom fastapi import FastAPI, Depends, HTTPException, status\nfrom fastapi.security import OAuth2AuthorizationCodeBearer\nimport os\nimport httpx\nfrom sqlalchemy import create_engine, Column, Integer, String\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\n\napp = FastAPI()\n\n# Auth0 configuration\nauth0_domain = os.getenv(\"AUTH0_DOMAIN\")\nauth0_client_id = os.getenv(\"AUTH0_CLIENT_ID\")\nauth0_client_secret = os.getenv(\"AUTH0_CLIENT_SECRET\")\n\noauth2_scheme = OAuth2AuthorizationCodeBearer(\n    authorizationUrl=f\"https://{auth0_domain}/authorize\",\n    tokenUrl=f\"https://{auth0_domain}/oauth/token\"\n)\n\n# Database configuration\ndatabase_url = f\"postgresql://{os.getenv('PGUSER')}:{os.getenv('PGPASSWORD')}@{os.getenv('PGHOST')}/{os.getenv('PGDATABASE')}\"\nengine = create_engine(database_url)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = declarative_base()\n\nclass Item(Base):\n    __tablename__ = \"items\"\n    id = Column(Integer, primary_key=True, index=True)\n    name = Column(String, index=True)\n    description = Column(String)\n\nBase.metadata.create_all(bind=engine)\n\n# Health check endpoint for Knative\n@app.get(\"/healthz/concurrency\")\nasync def health_check():\n    return {\"status\": \"ok\"}\n\n# Metrics endpoint for Prometheus\n@app.get(\"/metrics\")\nasync def metrics():\n    return {\"requests_total\": 0}\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Hello World\"}\n\n@app.get(\"/items/\")\nasync def read_items(token: str = Depends(oauth2_scheme)):\n    # Verify token with Auth0\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\n            f\"https://{auth0_domain}/userinfo\",\n            headers={\"Authorization\": f\"Bearer {token}\"}\n        )\n        if response.status_code != 200:\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Invalid authentication credentials\"\n            )\n    \n    # Query database\n    db = SessionLocal()\n    items = db.query(Item).all()\n    db.close()\n    return items\n```\n\n**Dockerfile for Python/FastAPI:**\n```dockerfile\n# Build stage\nFROM python:3.11-slim AS builder\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip wheel --no-cache-dir --no-deps --wheel-dir /app/wheels -r requirements.txt\n\n# Final stage\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY --from=builder /app/wheels /wheels\nCOPY --from=builder /app/requirements.txt .\n\nRUN pip install --no-cache /wheels/*\n\nCOPY . .\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n```\n\nImplement similar templates for Java/Spring Boot with appropriate structure and configuration. Include documentation and examples for common use cases.",
        "testStrategy": "1. Test template repositories with sample data\n2. Verify Auth0 integration works correctly\n3. Test Neon Postgres connection and queries\n4. Validate health check and metrics endpoints\n5. Test Dockerfile builds and runs correctly\n6. Verify that environment variables are properly used\n7. Test with various configuration options",
        "priority": "medium",
        "dependencies": [
          15,
          19
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Python/FastAPI Template Repository Structure",
            "description": "Set up a complete template repository for Python/FastAPI applications with proper directory structure, configuration files, and basic application setup.",
            "dependencies": [],
            "details": "Create a new GitHub repository with the following structure:\n- `/app`: Main application code\n- `/tests`: Unit and integration tests\n- `/docs`: Documentation\n- `requirements.txt`: Dependencies\n- `requirements-dev.txt`: Development dependencies\n- `.env.example`: Example environment variables\n- `.gitignore`: Configured for Python\n- `README.md`: Setup and usage instructions\n\nImplement the FastAPI application with proper structure including routes, models, and services directories. Include configuration for environment variables loading and logging.",
            "status": "pending",
            "testStrategy": "Create basic pytest tests to verify the application structure loads correctly and health endpoints respond."
          },
          {
            "id": 2,
            "title": "Create Java/Spring Boot Template Repository Structure",
            "description": "Set up a complete template repository for Java/Spring Boot applications with proper directory structure, configuration files, and basic application setup.",
            "dependencies": [],
            "details": "Create a new GitHub repository with Maven/Gradle project structure:\n- `src/main/java`: Main application code with package structure\n- `src/main/resources`: Configuration files (application.properties/yml)\n- `src/test`: Test classes\n- `.gitignore`: Configured for Java\n- `README.md`: Setup and usage instructions\n\nImplement Spring Boot application with proper structure including controllers, services, repositories, and models. Include configuration for profiles (dev, prod) and logging.",
            "status": "pending",
            "testStrategy": "Create JUnit tests to verify the application structure loads correctly and health endpoints respond."
          },
          {
            "id": 3,
            "title": "Implement Multi-stage Dockerfiles and Docker Compose",
            "description": "Create optimized Dockerfiles for both Python and Java templates with multi-stage builds and Docker Compose configurations for local development.",
            "dependencies": [
              1,
              2
            ],
            "details": "For Python/FastAPI:\n- Create multi-stage Dockerfile as shown in the example\n- Add Docker Compose file with Postgres service for local development\n\nFor Java/Spring Boot:\n- Create multi-stage Dockerfile using Maven/Gradle build and JRE runtime\n- Add Docker Compose file with Postgres service for local development\n\nBoth should include:\n- Health check configurations\n- Environment variable handling\n- Proper security practices (non-root user, etc.)\n- Volume mounts for development",
            "status": "pending",
            "testStrategy": "Build images and verify they run correctly with docker-compose up. Test hot-reloading in development mode."
          },
          {
            "id": 4,
            "title": "Implement Auth0 Integration for Both Templates",
            "description": "Add complete Auth0 integration to both template applications including configuration, middleware/filters, and example protected routes.",
            "dependencies": [
              1,
              2
            ],
            "details": "For Python/FastAPI:\n- Implement Auth0 authentication using the OAuth2AuthorizationCodeBearer\n- Add middleware for token validation\n- Create example protected and public routes\n\nFor Java/Spring Boot:\n- Implement Auth0 authentication using Spring Security\n- Configure security filters for JWT validation\n- Create example protected and public endpoints\n\nBoth should include:\n- Clear documentation on Auth0 setup requirements\n- Environment variable configuration\n- Role-based access control examples",
            "status": "pending",
            "testStrategy": "Create tests with mock Auth0 responses to verify authentication and authorization flows."
          },
          {
            "id": 5,
            "title": "Implement Neon Postgres Connection and Observability",
            "description": "Add database connection configuration for Neon Postgres and implement health checks, metrics, and logging for observability.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "For Python/FastAPI:\n- Configure SQLAlchemy for Neon Postgres connection with connection pooling\n- Add Prometheus metrics endpoint\n- Implement structured logging\n- Add health check endpoints for Knative\n\nFor Java/Spring Boot:\n- Configure Spring Data JPA for Neon Postgres connection\n- Add Micrometer/Prometheus integration\n- Configure structured JSON logging\n- Implement Spring Boot Actuator endpoints\n\nBoth should include:\n- Database migration tools (Alembic for Python, Flyway/Liquibase for Java)\n- Connection retry logic\n- Example entity/model and repository\n- Documentation on connection string format for Neon",
            "status": "pending",
            "testStrategy": "Create integration tests with test containers to verify database connectivity. Test metrics endpoints return proper format."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-07-06T18:51:13.961Z",
      "updated": "2025-07-07T16:08:59.574Z",
      "description": "Tasks for master context"
    }
  }
}