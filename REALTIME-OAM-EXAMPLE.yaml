# Comprehensive Realtime OAM Application Example
# This demonstrates ALL features of the realtime-platform ComponentDefinition
# including advanced configuration, scaling, security, and analytics

apiVersion: core.oam.dev/v1beta1
kind: Application
metadata:
  name: comprehensive-realtime-app
  namespace: production
  annotations:
    oam.dev/description: "Comprehensive example showcasing all realtime platform features"
    oam.dev/version: "1.0.0"
    oam.dev/maintainer: "Platform Team"
    oam.dev/use-case: "Production health data streaming with IoT devices"
spec:
  components:
  
  # ============================================================================
  # COMPONENT 1: Advanced Realtime Platform with Full Configuration
  # ============================================================================
  - name: health-platform
    type: realtime-platform
    properties:
      name: health-data-streaming
      database: postgres
      visualization: metabase
      iot: true
      
      # Advanced Lenses Configuration
      lensesConfig:
        licenseKey: "your-lenses-license-key-here"
        heapSize: "2048m"
        enableUI: true
      
      # Advanced MQTT Configuration for Health Devices
      mqttConfig:
        users:
          # Production health monitoring devices
          - username: blood-pressure-monitor
            password: "bp-device-secure-2024"
          - username: heart-rate-sensor
            password: "hr-sensor-secure-2024"
          - username: oxygen-saturation-device
            password: "o2-device-secure-2024"
          - username: temperature-probe
            password: "temp-probe-secure-2024"
          # Mobile applications
          - username: health-mobile-app
            password: "mobile-app-secure-2024"
          # Analytics services
          - username: analytics-service
            password: "analytics-secure-2024"
        persistenceSize: "50Gi"
        enableWebSockets: true
        qosLevel: 1
      
      # Advanced Kafka Configuration for Health Data
      kafkaConfig:
        topics:
          # Device data topics
          - "blood_pressure_readings"
          - "heart_rate_readings"
          - "oxygen_saturation_readings"
          - "temperature_readings"
          # Processed data topics
          - "health_alerts"
          - "daily_summaries"
          - "trend_analysis"
          # System topics
          - "device_status"
          - "audit_logs"
        retention: "30d"  # 30 days for compliance
        partitions: 10
        replicationFactor: 3
      
      # Snowflake Integration for Advanced Analytics
      snowflakeConfig:
        enabled: true
        credentialsSecret: "snowflake-health-analytics"
        database: "HEALTH_ANALYTICS"
        schema: "STREAMING_DATA"
      
      # Production Resource Allocation
      resources:
        cpu: "8000m"
        memory: "16Gi"
      
      # Auto-scaling Configuration
      scaling:
        minReplicas: 3
        maxReplicas: 10
        targetCPU: 70

  # ============================================================================
  # COMPONENT 2: Health Data Processing Service
  # ============================================================================
  - name: health-processor
    type: webservice
    properties:
      name: health-data-processor
      language: python
      framework: fastapi
      image: "socrates12345/health-data-processor:v2.1.0"
      
      # Connect to the realtime platform
      realtime: "health-data-streaming"
      websocket: true
      
      # Advanced streaming configuration
      streaming:
        enabled: true
        topics:
          - "blood_pressure_readings"
          - "heart_rate_readings"
          - "oxygen_saturation_readings"
          - "temperature_readings"
        consumerGroup: "health-processor-group"
        autoOffsetReset: "earliest"
        sessionTimeoutMs: 30000
        heartbeatIntervalMs: 3000
        maxPollRecords: 500
      
      # Health-specific environment variables
      environment:
        SERVICE_TYPE: "HEALTH_DATA_PROCESSOR"
        PROCESSING_MODE: "REALTIME"
        ALERT_THRESHOLDS: |
          {
            "heartRate": {"min": 60, "max": 100},
            "bloodPressure": {"systolic_max": 140, "diastolic_max": 90},
            "oxygenSaturation": {"min": 95},
            "temperature": {"min": 36.1, "max": 37.2}
          }
        WEBSOCKET_ENDPOINTS: "/ws/health,/ws/alerts,/ws/trends"
        ML_MODEL_ENABLED: "true"
        ANOMALY_DETECTION_ENABLED: "true"
        BATCH_SIZE: "100"
        PROCESSING_INTERVAL: "5s"
      
      # Production resource requirements
      resources:
        cpu: "2000m"
        memory: "4Gi"
        storage: "10Gi"
    
    traits:
    - type: ingress
      properties:
        domain: health-processor.production.local
        path: "/"
        https: true
        annotations:
          nginx.ingress.kubernetes.io/rate-limit: "100"
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
    
    - type: autoscaler
      properties:
        minReplicas: 2
        maxReplicas: 8
        targetCPUUtilization: 80
        targetMemoryUtilization: 85

  # ============================================================================
  # COMPONENT 3: Real-time Alert Service
  # ============================================================================
  - name: alert-service
    type: webservice
    properties:
      name: health-alert-service
      language: python
      framework: fastapi
      image: "socrates12345/health-alert-service:v1.5.2"
      
      # Connect to the same realtime platform
      realtime: "health-data-streaming"
      websocket: true
      
      # Alert-specific streaming configuration
      streaming:
        enabled: true
        topics:
          - "health_alerts"
          - "device_status"
        consumerGroup: "alert-service-group"
        enableAutoCommit: false
        maxPollIntervalMs: 300000
      
      # Alert service configuration
      environment:
        SERVICE_TYPE: "HEALTH_ALERT_SERVICE"
        ALERT_CHANNELS: "email,sms,push,websocket"
        EMAIL_SMTP_HOST: "smtp.healthcare.local"
        SMS_PROVIDER: "twilio"
        PUSH_NOTIFICATION_ENABLED: "true"
        ESCALATION_ENABLED: "true"
        ALERT_SUPPRESSION_WINDOW: "300s"
        MAX_ALERTS_PER_MINUTE: "10"
        WEBSOCKET_ENDPOINT: "/ws/alerts"
      
      resources:
        cpu: "1000m"
        memory: "2Gi"
    
    traits:
    - type: ingress
      properties:
        domain: alerts.production.local
        path: "/"
        https: true

  # ============================================================================
  # COMPONENT 4: Analytics Dashboard Service
  # ============================================================================
  - name: analytics-dashboard
    type: webservice
    properties:
      name: health-analytics-dashboard
      language: python
      framework: streamlit
      image: "socrates12345/health-analytics-dashboard:v3.0.1"
      
      # Connect to realtime platform for live data
      realtime: "health-data-streaming"
      
      # Dashboard-specific streaming
      streaming:
        enabled: true
        topics:
          - "daily_summaries"
          - "trend_analysis"
        consumerGroup: "dashboard-group"
      
      # Analytics configuration
      environment:
        SERVICE_TYPE: "HEALTH_ANALYTICS_DASHBOARD"
        DASHBOARD_TYPE: "STREAMLIT"
        CHART_TYPES: "timeseries,histogram,heatmap,scatter"
        REFRESH_INTERVAL: "30s"
        DATA_RETENTION_DAYS: "90"
        EXPORT_FORMATS: "pdf,csv,json"
        SHARING_ENABLED: "true"
        REALTIME_UPDATES: "true"
        SNOWFLAKE_ENABLED: "true"
      
      resources:
        cpu: "500m"
        memory: "1Gi"
    
    traits:
    - type: ingress
      properties:
        domain: analytics.production.local
        path: "/"
        https: true

  # ============================================================================
  # COMPONENT 5: IoT Device Simulator (for testing)
  # ============================================================================
  - name: device-simulator
    type: webservice
    properties:
      name: health-device-simulator
      language: python
      framework: fastapi
      image: "socrates12345/health-device-simulator:v1.2.0"
      
      # Connect to realtime platform to send test data
      realtime: "health-data-streaming"
      
      # Simulator configuration
      environment:
        SERVICE_TYPE: "DEVICE_SIMULATOR"
        SIMULATION_MODE: "REALISTIC"
        DEVICE_COUNT: "50"
        MESSAGE_INTERVAL: "10s"
        DEVICE_TYPES: "blood_pressure,heart_rate,oxygen_saturation,temperature"
        ANOMALY_INJECTION_RATE: "0.05"  # 5% anomalies for testing
        MQTT_TOPICS: |
          {
            "blood_pressure": "health/blood_pressure",
            "heart_rate": "health/heart_rate",
            "oxygen_saturation": "health/oxygen_saturation",
            "temperature": "health/temperature"
          }
      
      resources:
        cpu: "500m"
        memory: "512Mi"
    
    traits:
    - type: ingress
      properties:
        domain: simulator.production.local
        path: "/"
        https: true

  # ============================================================================
  # COMPONENT 6: Data Export Service
  # ============================================================================
  - name: data-export
    type: webservice
    properties:
      name: health-data-export
      language: python
      framework: fastapi
      image: "socrates12345/health-data-export:v1.1.0"
      
      # Connect to platform for data access
      realtime: "health-data-streaming"
      
      # Export service configuration
      environment:
        SERVICE_TYPE: "DATA_EXPORT_SERVICE"
        EXPORT_FORMATS: "csv,json,parquet,avro"
        BATCH_EXPORT_ENABLED: "true"
        REALTIME_EXPORT_ENABLED: "true"
        COMPRESSION_ENABLED: "true"
        ENCRYPTION_ENABLED: "true"
        MAX_EXPORT_SIZE: "100MB"
        EXPORT_RETENTION_DAYS: "7"
        S3_BUCKET: "health-data-exports"
        SNOWFLAKE_EXPORT_ENABLED: "true"
      
      resources:
        cpu: "1000m"
        memory: "2Gi"
        storage: "5Gi"
    
    traits:
    - type: ingress
      properties:
        domain: export.production.local
        path: "/"
        https: true

  policies:
  # ============================================================================
  # TOPOLOGY POLICIES - Define deployment relationships
  # ============================================================================
  - name: health-topology
    type: topology
    properties:
      clusters: ["production-cluster"]
      namespace: production
      placement:
        # Platform components on dedicated nodes
        health-platform:
          nodeSelector:
            node-type: "high-memory"
            zone: "us-east-1a"
        # Processing services distributed
        health-processor:
          nodeSelector:
            node-type: "compute-optimized"
        alert-service:
          nodeSelector:
            node-type: "standard"
        # Analytics on dedicated analytics nodes
        analytics-dashboard:
          nodeSelector:
            node-type: "analytics"

  # ============================================================================
  # SECURITY POLICIES
  # ============================================================================
  - name: health-security
    type: security-policy
    properties:
      # Network security
      networkPolicies:
        - name: health-platform-access
          spec:
            podSelector:
              matchLabels:
                app.oam.dev/component: health-platform
            policyTypes: ["Ingress", "Egress"]
            ingress:
            - from:
              - podSelector:
                  matchLabels:
                    app.oam.dev/name: health-data-streaming
            egress:
            - to: []
              ports:
              - protocol: TCP
                port: 5432  # PostgreSQL
              - protocol: TCP
                port: 9092  # Kafka
              - protocol: TCP
                port: 1883  # MQTT
      
      # RBAC configuration
      rbac:
        serviceAccount: health-platform-sa
        rules:
        - apiGroups: [""]
          resources: ["secrets", "configmaps"]
          verbs: ["get", "list", "watch"]
        - apiGroups: ["apps"]
          resources: ["deployments"]
          verbs: ["get", "list", "watch", "update"]

  # ============================================================================
  # MONITORING AND OBSERVABILITY POLICIES
  # ============================================================================
  - name: health-monitoring
    type: monitoring
    properties:
      # Prometheus metrics
      metrics:
        enabled: true
        path: "/metrics"
        port: 8080
        scrapeInterval: "30s"
        customMetrics:
        - name: "health_readings_total"
          help: "Total number of health readings processed"
          type: "counter"
        - name: "health_alerts_active"
          help: "Number of active health alerts"
          type: "gauge"
        - name: "device_connectivity_status"
          help: "Device connectivity status"
          type: "gauge"
      
      # Distributed tracing
      tracing:
        enabled: true
        jaeger:
          endpoint: "http://jaeger-collector:14268/api/traces"
          samplingRate: 0.1
      
      # Logging configuration
      logging:
        level: "INFO"
        format: "json"
        destination: "elasticsearch"
        retention: "30d"
        fields:
        - "timestamp"
        - "level"
        - "service"
        - "trace_id"
        - "span_id"
        - "message"
        - "patient_id"  # Health-specific
        - "device_id"   # Health-specific

  # ============================================================================
  # BACKUP AND DISASTER RECOVERY POLICIES
  # ============================================================================
  - name: health-backup
    type: backup
    properties:
      # Database backup
      databases:
      - name: health-postgres
        schedule: "0 2 * * *"  # Daily at 2 AM
        retention: "30d"
        encryption: true
        compression: true
      
      # Kafka topic backup
      kafkaTopics:
      - topics: ["blood_pressure_readings", "heart_rate_readings"]
        schedule: "0 3 * * *"  # Daily at 3 AM
        retention: "90d"
        destination: "s3://health-kafka-backups"
      
      # Configuration backup
      configurations:
        schedule: "0 1 * * *"  # Daily at 1 AM
        items: ["secrets", "configmaps", "applications"]
        retention: "90d"

  # ============================================================================
  # SCALING POLICIES
  # ============================================================================
  - name: health-scaling
    type: override
    properties:
      components:
      - name: health-processor
        traits:
        - type: hpa
          properties:
            minReplicas: 2
            maxReplicas: 20
            metrics:
            - type: Resource
              resource:
                name: cpu
                target:
                  type: Utilization
                  averageUtilization: 70
            - type: Resource
              resource:
                name: memory
                target:
                  type: Utilization
                  averageUtilization: 80
            - type: Pods
              pods:
                metric:
                  name: kafka_consumer_lag
                target:
                  type: AverageValue
                  averageValue: "100"
      
      - name: alert-service
        traits:
        - type: hpa
          properties:
            minReplicas: 2
            maxReplicas: 10
            metrics:
            - type: Resource
              resource:
                name: cpu
                target:
                  type: Utilization
                  averageUtilization: 60

---
# ============================================================================
# ALTERNATIVE: Using Multiple Specialized IoT Components
# This demonstrates using the individual iot-broker, stream-processor, and
# analytics-dashboard components instead of the all-in-one realtime-platform
# ============================================================================
apiVersion: core.oam.dev/v1beta1
kind: Application
metadata:
  name: modular-realtime-app
  namespace: staging
  annotations:
    oam.dev/description: "Modular approach using individual components"
spec:
  components:
  
  # Specialized IoT Broker for Health Devices
  - name: health-iot-broker
    type: iot-broker
    properties:
      name: health-device-network
      mqttPort: 1883
      websocketPort: 9001
      
      authentication:
        enabled: true
        users:
          - username: bp-monitor-001
            password: "secure-bp-001"
          - username: hr-sensor-002
            password: "secure-hr-002"
          - username: temp-probe-003
            password: "secure-temp-003"
      
      topics:
        - "health/blood_pressure"
        - "health/heart_rate"
        - "health/temperature"
        - "health/oxygen_saturation"
      
      connector:
        enabled: true
        kafkaTopic: "health_device_data"
        mqttTopic: "health/+"
        keyField: "deviceId"
        qos: 1
        errorPolicy: "RETRY"
      
      persistence:
        enabled: true
        size: "10Gi"

  # Advanced Stream Processing
  - name: health-stream-processor
    type: stream-processor
    properties:
      name: health-analytics-engine
      
      queries:
        - name: vital-signs-aggregation
          sql: |
            INSERT INTO vital_signs_summary
            SELECT STREAM
                _value.patientId AS _key,
                STRUCT(
                  patientId := _value.patientId,
                  avgHeartRate := AVG(_value.heartRate),
                  maxSystolic := MAX(_value.systolic),
                  minOxygenSat := MIN(_value.oxygenSaturation),
                  avgTemperature := AVG(_value.temperature),
                  readingCount := COUNT(*),
                  windowStart := TUMBLE_START(ROWTIME, INTERVAL '5' MINUTES),
                  windowEnd := TUMBLE_END(ROWTIME, INTERVAL '5' MINUTES)
                ) AS _value
            FROM health_device_data
            WHERE _value.patientId IS NOT NULL
            GROUP BY _value.patientId, TUMBLE(ROWTIME, INTERVAL '5' MINUTES)
        
        - name: anomaly-detection
          sql: |
            INSERT INTO health_anomalies
            SELECT STREAM *
            FROM health_device_data
            WHERE _value.heartRate > 120 OR _value.heartRate < 50
               OR _value.systolic > 160 OR _value.diastolic > 100
               OR _value.oxygenSaturation < 90
               OR _value.temperature > 38.5 OR _value.temperature < 35.0
        
        - name: device-health-monitoring
          sql: |
            INSERT INTO device_status_summary
            SELECT STREAM
                _value.deviceId AS _key,
                STRUCT(
                  deviceId := _value.deviceId,
                  lastSeen := MAX(ROWTIME),
                  messageCount := COUNT(*),
                  batteryLevel := LATEST_BY_OFFSET(_value.batteryLevel),
                  signalStrength := AVG(_value.signalStrength),
                  errorCount := SUM(CASE WHEN _value.errorCode IS NOT NULL THEN 1 ELSE 0 END)
                ) AS _value
            FROM health_device_data
            GROUP BY _value.deviceId, TUMBLE(ROWTIME, INTERVAL '1' HOUR)
      
      topics:
        input: ["health_device_data"]
        output: ["vital_signs_summary", "health_anomalies", "device_status_summary"]
      
      errorHandling:
        policy: "DEAD_LETTER"
        retries: 3
        deadLetterTopic: "health_processing_errors"
      
      processing:
        parallelism: 4
        checkpointInterval: "60s"
        stateBackend: "rocksdb"

  # Specialized Analytics Dashboard
  - name: health-analytics-dashboard
    type: analytics-dashboard
    properties:
      name: health-insights
      dashboardType: metabase
      
      dataSources:
        - name: health-kafka-streams
          type: kafka
          connectionString: "kafka://health-kafka:9092"
        - name: health-postgres
          type: postgres
          secretRef: "health-db-secret"
        - name: health-snowflake
          type: snowflake
          secretRef: "health-snowflake-secret"
      
      dashboards:
        - name: patient-overview
          template: "healthcare-patient-dashboard"
          autoCreate: true
        - name: device-monitoring
          template: "iot-device-monitoring"
          autoCreate: true
        - name: real-time-vitals
          template: "real-time-health-metrics"
          autoCreate: true
        - name: anomaly-alerts
          template: "health-anomaly-detection"
          autoCreate: true
      
      alerts:
        enabled: true
        channels:
          - type: email
            config:
              recipients: ["medical-team@hospital.com", "it-ops@hospital.com"]
          - type: slack
            config:
              webhook: "https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX"
          - type: webhook
            config:
              url: "https://pager-duty.hospital.com/webhook"
              headers:
                Authorization: "Bearer pagerduty-token"
      
      authentication:
        enabled: true
        provider: "oauth"
        config:
          oauthProvider: "okta"
          clientId: "health-dashboard-client"
          clientSecret: "oauth-client-secret"

---
# ============================================================================
# PRODUCTION DEPLOYMENT EXAMPLE
# This shows how to use environment-specific configurations
# ============================================================================
apiVersion: core.oam.dev/v1beta1
kind: Application
metadata:
  name: health-realtime-production
  namespace: production
  labels:
    environment: production
    compliance: hipaa
    criticality: high
spec:
  components:
  
  # Production-grade realtime platform
  - name: production-health-platform
    type: realtime-platform
    properties:
      name: prod-health-streaming
      database: postgres
      visualization: metabase
      iot: true
      
      # Production Lenses configuration
      lensesConfig:
        licenseKey: "prod-lenses-license-key"
        heapSize: "4096m"
        enableUI: true
      
      # High-security MQTT configuration
      mqttConfig:
        users:
          - username: prod-bp-monitor
            password: "complex-production-password-bp-2024"
          - username: prod-hr-sensor
            password: "complex-production-password-hr-2024"
          - username: prod-o2-sensor
            password: "complex-production-password-o2-2024"
        persistenceSize: "100Gi"
        enableWebSockets: true
        qosLevel: 2  # Highest QoS for production
      
      # Production Kafka configuration
      kafkaConfig:
        topics:
          - "prod_blood_pressure_readings"
          - "prod_heart_rate_readings"
          - "prod_oxygen_saturation_readings"
          - "prod_health_alerts"
          - "prod_audit_logs"
        retention: "365d"  # 1 year retention for compliance
        partitions: 20
        replicationFactor: 3
      
      # Snowflake production integration
      snowflakeConfig:
        enabled: true
        credentialsSecret: "snowflake-prod-health"
        database: "PROD_HEALTH_ANALYTICS"
        schema: "REAL_TIME_STREAMING"
      
      # High-availability resource allocation
      resources:
        cpu: "16000m"
        memory: "32Gi"
      
      # Production scaling
      scaling:
        minReplicas: 5
        maxReplicas: 20
        targetCPU: 60

  # Production health processing service
  - name: prod-health-processor
    type: webservice
    properties:
      name: prod-health-data-processor
      language: python
      framework: fastapi
      image: "socrates12345/health-data-processor:v2.1.0-prod"
      
      realtime: "prod-health-streaming"
      websocket: true
      
      streaming:
        enabled: true
        topics:
          - "prod_blood_pressure_readings"
          - "prod_heart_rate_readings"
          - "prod_oxygen_saturation_readings"
        consumerGroup: "prod-health-processor-group"
        autoOffsetReset: "earliest"
        enableAutoCommit: false
        maxPollRecords: 1000
        sessionTimeoutMs: 60000
      
      environment:
        SERVICE_TYPE: "PRODUCTION_HEALTH_PROCESSOR"
        ENVIRONMENT: "PRODUCTION"
        COMPLIANCE_MODE: "HIPAA"
        ENCRYPTION_ENABLED: "true"
        AUDIT_LOGGING_ENABLED: "true"
        ALERT_THRESHOLDS: |
          {
            "heartRate": {"critical_low": 40, "critical_high": 150, "warning_low": 50, "warning_high": 120},
            "bloodPressure": {"critical_systolic": 180, "critical_diastolic": 110, "warning_systolic": 140, "warning_diastolic": 90},
            "oxygenSaturation": {"critical_low": 85, "warning_low": 90},
            "temperature": {"critical_low": 32.0, "critical_high": 42.0, "warning_low": 35.0, "warning_high": 38.5}
          }
        ML_MODEL_VERSION: "v3.2.1"
        ANOMALY_DETECTION_SENSITIVITY: "high"
        REAL_TIME_PROCESSING: "true"
        BATCH_PROCESSING: "true"
        DATA_VALIDATION_ENABLED: "true"
      
      resources:
        cpu: "4000m"
        memory: "8Gi"
        storage: "50Gi"
    
    traits:
    - type: ingress
      properties:
        domain: health-processor.prod.hospital.local
        path: "/"
        https: true
        annotations:
          nginx.ingress.kubernetes.io/ssl-ciphers: "ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512"
          nginx.ingress.kubernetes.io/ssl-protocols: "TLSv1.2 TLSv1.3"
          nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    
    - type: autoscaler
      properties:
        minReplicas: 3
        maxReplicas: 15
        targetCPUUtilization: 70
        targetMemoryUtilization: 80
        behavior:
          scaleUp:
            stabilizationWindowSeconds: 60
            policies:
            - type: Percent
              value: 100
              periodSeconds: 15
          scaleDown:
            stabilizationWindowSeconds: 300
            policies:
            - type: Percent
              value: 10
              periodSeconds: 60